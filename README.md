## ç°¡ä»‹/Introduction

é€éLocal LLMã€RAGã€TTSã€STTç­‰æŠ€è¡“æ‰€å®Œæˆçš„å°ˆæ¡ˆ 
> This project was made by Local LLMã€RAGã€TTS and STT

>[!NOTE]
>æ­¤é …å°ˆæ¡ˆåˆ©ç”¨Meta æå‡ºçš„llama_cppå¥—ä»¶å¼•ç”¨ Hugging face ä¸­çš„ pre-trained model(Mistral 7B)
>
>This project utilizes the llama_cpp library proposed by Meta to reference the pre-trained model (Mistral 7B) from Hugging Face.
>
>---
>[pre-trained model](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF)
>### Pytorch
>å»ºè­°å®‰è£CUDAç‰ˆæœ¬
>
> recommend running this project using the CUDA version of PyTorch.
>
>---

>[!important]
>llama_cpp ä½¿ç”¨æ•™å­¸
>
>llama_cpp tutorial
>
>[Run Llama 2 Locally with python](https://swharden.com/blog/2023-07-29-ai-chat-locally-with-python/)

>*æ¬Šé‡/weight*
>
>[mistral-7b-instruct-v0.1.Q3_K_M.gguf](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/blob/main/mistral-7b-instruct-v0.1.Q3_K_M.gguf)
>
>å°‡ä¸‹è¼‰çš„æ¬Šé‡æ”¾ç½®æ–¼
>Place your weight under the LLM_weight
>```bash
>TTS-System
>    â””â”€â”€backEnd
>          â””â”€â”€LLM_weight
>                â””â”€â”€ .gguf file
>```
>
---
**é è¦½/preview**
>[!NOTE]
> ### åŸºç¤ä½¿ç”¨
> ä½¿ç”¨è€…å¯ä»¥é€éæ–‡å­—è¼¸å…¥æˆ–èªéŸ³è¼¸å…¥èˆ‡ç³»çµ±äº’å‹•ï¼Œç³»çµ±æœƒä»¥èªéŸ³åŠ æ–‡å­—çš„æ–¹å¼é€²è¡Œå›é¥‹
>
>Users can interact with the system by speaking or typing, and will receive feedback through voice and text.
>
>---
>### RAG
>ä½¿ç”¨è€…å¯ä»¥é€éä¸Šå‚³TXTæª”çš„æ–¹å¼ä½¿ç³»çµ±å›ç­”å¾—æ›´åŠ æº–ç¢º
>
>Users can get hight qulity response by upload txt file.
>
>---
>### Embedding
>
>Sentence Transformersï¼š[sentence_transformers](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)
>
>é€™é …å°ˆæ¡ˆä½¿ç”¨ sentence_transformers ä½œç‚ºè©å‘é‡è½‰æ›çš„å¥—ä»¶ï¼Œä¸¦åˆ©ç”¨é¤˜å¼¦ç›¸ä¼¼åº¦ç®—å‡ºå‰ K å€‹ç›¸é—œçš„è³‡è¨Šæä¾›çµ¦prompt
>
>
>This project uses the sentence_transformers library for word embeddings and employs cosine similarity to calculate the top K relevant pieces of information to provide for the prompt.
>
---







![preview](https://github.com/ImChouOWO/TTS-Systeam/blob/main/img/img%201.png)

---



## å¼•ç”¨å°ˆæ¡ˆ/inference

> [!NOTE]
> [**VALL-E-X**](https://github.com/Plachtaa/VALL-E-X)


## å¦‚ä½•åŸ·è¡Œ/How to run this project

ğŸ’¡ **ç‚ºäº†ç¢ºä¿èªéŸ³åˆæˆç›¸é—œåŠŸèƒ½å¯ä»¥ä½¿ç”¨ï¼Œè«‹å…ˆClone [VALL-E-X](https://github.com/Plachtaa/VALL-E-X) ä¸­çš„å°ˆæ¡ˆè‡ªè¡Œæ¸¬è©¦**

ğŸ’¡ **éœ€ç¢ºä¿èƒ½å¤ æ­£å¸¸å•Ÿç”¨React.JSç›¸é—œå°ˆæ¡ˆ**

ğŸ’¡ **éœ€å®‰è£FFMPEGç›¸é—œæª”æ¡ˆ**
> Clone  [VALL-E-X](https://github.com/Plachtaa/VALL-E-X)  and make sure you can run this project!!!
> 
> make sure React.JS can be use!!!
> 
> need to download FFMPEG

### é€²å…¥å°ˆæ¡ˆ/Enter the project
```bash
cd TTS-Systeam
```
### å‰µå»ºè™›æ“¬ç’°å¢ƒ/Create a virtual environment
```bash
python -m venv env
```
> [!NOTE]
> æ¿€æ´»è™›æ“¬ç’°å¢ƒ/Activate the virtual environment

> Unix/macOS
```bash
source env/bin/activate
```
> Windows
```bash
.\env\Scripts\activate 
```
### å®‰è£ä¾è³´åŒ…/Install dependencies

```bash
pip install -r requirements.txt
```
### å•Ÿå‹•å¾Œç«¯ä¼ºæœå™¨/Activate backend server
> é€™éƒ¨ä»½éœ€è¦å…©å€‹ Terminalï¼Œåˆ†åˆ¥ç”¨æ–¼å‰ç«¯èˆ‡å¾Œç«¯
> 
> This part need tow Terminal,one for backend, the other for front

```bash
cd backEnd
```

```bash
python main.py
```

### å•Ÿå‹•å‰ç«¯UI/Activate front UI

```bash
cd web-tts
```

```bash
npm start
```
